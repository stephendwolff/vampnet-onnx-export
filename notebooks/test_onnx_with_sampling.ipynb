{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ONNX with Proper Sampling\n",
    "\n",
    "This notebook tests the new ONNX export that returns logits instead of using ArgMax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# First, export the new models\n",
    "from scripts.export_vampnet_transformer_v3_sampling import export_model_with_proper_sampling\n",
    "\n",
    "# Export coarse model with logits output\n",
    "export_model_with_proper_sampling(\"coarse\")\n",
    "export_model_with_proper_sampling(\"c2f\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport soundfile as sf\nimport onnxruntime as ort\nfrom pathlib import Path\n\nfrom scripts.export_vampnet_transformer_v3_sampling import sample_from_onnx_output\n\n# Load models\nencoder_session = ort.InferenceSession(\"../scripts/models/vampnet_encoder_prepadded.onnx\")\ndecoder_session = ort.InferenceSession(\"../scripts/models/vampnet_codec_decoder.onnx\")\ncoarse_session = ort.InferenceSession(\"../onnx_models_fixed/coarse_logits_v3.onnx\")\nc2f_session = ort.InferenceSession(\"../onnx_models_fixed/c2f_logits_v3.onnx\")\n\nprint(\"Models loaded\")\n\n# Check input names for each model\nprint(\"\\nModel inputs:\")\nprint(f\"  Coarse: {[inp.name for inp in coarse_session.get_inputs()]}\")\nprint(f\"  C2F: {[inp.name for inp in c2f_session.get_inputs()]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test audio\n",
    "n_samples = 76800  # 100 tokens\n",
    "sample_rate = 44100\n",
    "t = np.linspace(0, n_samples/sample_rate, n_samples)\n",
    "audio = 0.5 * np.sin(2 * np.pi * 440 * t).astype(np.float32)\n",
    "\n",
    "# Encode\n",
    "codes = encoder_session.run(None, {'audio_padded': audio.reshape(1, 1, -1)})[0]\n",
    "print(f\"Encoded shape: {codes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test iterative generation with proper sampling\nmask_schedule = [0.9, 0.7, 0.5, 0.3, 0.1, 0.0]\nz = codes.copy()\nn_coarse = 4\n\nprint(\"Running iterative generation with proper sampling...\")\n\nfor i, mask_ratio in enumerate(mask_schedule):\n    print(f\"\\nStep {i+1}: mask_ratio = {mask_ratio}\")\n    \n    if mask_ratio > 0:\n        # Create mask\n        mask = np.random.rand(1, n_coarse, 100) < mask_ratio\n        \n        # Get logits from ONNX\n        logits = coarse_session.run(None, {\n            'codes': z[:, :n_coarse, :].astype(np.int64),\n            'mask': mask.astype(bool)\n        })[0]\n        \n        print(f\"  Logits shape: {logits.shape}\")\n        \n        # Apply proper sampling\n        z_new = sample_from_onnx_output(\n            z[:, :n_coarse, :], \n            mask,\n            logits,\n            temperature=0.8,\n            top_p=0.9\n        )\n        \n        # Update coarse codes\n        z[:, :n_coarse, :] = z_new\n        \n        # Count changes\n        n_changed = (z != codes).sum()\n        print(f\"  Changed {n_changed} tokens\")\n\n# Apply C2F\nprint(\"\\nApplying C2F...\")\nc2f_mask = np.zeros((1, 14, 100), dtype=bool)\nc2f_mask[:, 4:, :] = True\n\n# Pad z to 14 codebooks\nz_full = np.zeros((1, 14, 100), dtype=np.int64)\nz_full[:, :4, :] = z[:, :4, :]\n\n# Check if C2F expects mask input\nc2f_inputs = {inp.name: None for inp in c2f_session.get_inputs()}\nprint(f\"C2F expects inputs: {list(c2f_inputs.keys())}\")\n\n# Get C2F logits\nif 'mask' in c2f_inputs:\n    c2f_logits = c2f_session.run(None, {\n        'codes': z_full,\n        'mask': c2f_mask\n    })[0]\nelse:\n    # C2F doesn't expect mask - it's baked into the model\n    c2f_logits = c2f_session.run(None, {\n        'codes': z_full\n    })[0]\n\nprint(f\"C2F logits shape: {c2f_logits.shape}\")\n\n# Apply sampling\nz_final = sample_from_onnx_output(\n    z_full,\n    c2f_mask,\n    c2f_logits,\n    temperature=0.8,\n    top_p=0.9,\n    n_conditioning_codebooks=4\n)\n\n# Decode\naudio_generated = decoder_session.run(None, {'codes': z_final})[0]\naudio_generated = audio_generated[0, 0, :]\n\n# Save\noutput_dir = Path(\"outputs/sampling_test\")\noutput_dir.mkdir(exist_ok=True, parents=True)\n\nsf.write(output_dir / \"original.wav\", audio, sample_rate)\nsf.write(output_dir / \"generated_with_sampling.wav\", audio_generated, sample_rate)\n\nprint(f\"\\nSaved audio to {output_dir}\")\n\n# Plot\nfig, axes = plt.subplots(2, 1, figsize=(12, 6))\naxes[0].plot(audio[:4410])\naxes[0].set_title('Original')\naxes[1].plot(audio_generated[:4410])\naxes[1].set_title('Generated with Proper Sampling')\nplt.tight_layout()\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}