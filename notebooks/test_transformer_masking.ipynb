{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Masking Test with 100-Token Batch\n",
    "\n",
    "This notebook tests the VampNet transformer with different periodic masking patterns on the coarse layers using a single 100-token batch."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:15:36.580005Z",
     "start_time": "2025-06-13T15:15:32.184184Z"
    }
   },
   "source": "# Initialize VampNet\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Load VampNet interface\ninterface = vampnet.interface.Interface(\n    device=device,\n    codec_ckpt=\"../models/vampnet/codec.pth\",\n    coarse_ckpt=\"../models/vampnet/coarse.pth\",\n    wavebeat_ckpt=\"../models/vampnet/wavebeat.pth\"\n)\n\ncodec = interface.codec\ncoarse_model = interface.coarse\ncodec.eval()\ncoarse_model.eval()\n\nprint(\"\\nModels loaded:\")\nprint(f\"  Codec - Sample rate: {codec.sample_rate}, Hop length: {codec.hop_length}\")\nprint(f\"  Coarse model - n_codebooks: {coarse_model.n_codebooks}\")\nprint(f\"  Vocabulary size: {coarse_model.vocab_size}\")\n\n# Load ONNX models\nonnx_encoder_path = Path(\"../scripts/models/vampnet_encoder_prepadded.onnx\")\nonnx_coarse_path = Path(\"../onnx_models_fixed/coarse_complete_v3.onnx\")\n\nif not onnx_encoder_path.exists():\n    raise FileNotFoundError(f\"ONNX encoder not found at {onnx_encoder_path}\")\nif not onnx_coarse_path.exists():\n    raise FileNotFoundError(f\"ONNX coarse transformer not found at {onnx_coarse_path}\")\n\nonnx_encoder = ort.InferenceSession(str(onnx_encoder_path))\nonnx_coarse = ort.InferenceSession(str(onnx_coarse_path))\n\nprint(\"\\nONNX models loaded\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:15:46.059986Z",
     "start_time": "2025-06-13T15:15:36.584093Z"
    }
   },
   "source": [
    "# Initialize VampNet\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load VampNet interface\n",
    "interface = vampnet.interface.Interface(\n",
    "    device=device,\n",
    "    codec_ckpt=\"../models/vampnet/codec.pth\",\n",
    "    coarse_ckpt=\"../models/vampnet/coarse.pth\",\n",
    "    wavebeat_ckpt=\"../models/vampnet/wavebeat.pth\"\n",
    ")\n",
    "\n",
    "codec = interface.codec\n",
    "coarse_model = interface.coarse\n",
    "codec.eval()\n",
    "coarse_model.eval()\n",
    "\n",
    "print(\"\\nModels loaded:\")\n",
    "print(f\"  Codec - Sample rate: {codec.sample_rate}, Hop length: {codec.hop_length}\")\n",
    "print(f\"  Coarse model - n_codebooks: {coarse_model.n_codebooks}\")\n",
    "print(f\"  Vocabulary size: {coarse_model.vocab_size}\")\n",
    "\n",
    "# Load ONNX models\n",
    "onnx_encoder_path = Path(\"../scripts/models/vampnet_encoder_prepadded.onnx\")\n",
    "onnx_coarse_path = Path(\"../onnx_models_fixed/coarse_transformer_v2_weighted.onnx\")\n",
    "\n",
    "if not onnx_encoder_path.exists():\n",
    "    raise FileNotFoundError(f\"ONNX encoder not found at {onnx_encoder_path}\")\n",
    "if not onnx_coarse_path.exists():\n",
    "    raise FileNotFoundError(f\"ONNX coarse transformer not found at {onnx_coarse_path}\")\n",
    "\n",
    "onnx_encoder = ort.InferenceSession(str(onnx_encoder_path))\n",
    "onnx_coarse = ort.InferenceSession(str(onnx_coarse_path))\n",
    "\n",
    "print(\"\\nONNX models loaded\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/venv/lib/python3.11/site-packages/audiotools/ml/layers/base.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/venv/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.1.8 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../models/vampnet/wavebeat.pth`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models loaded:\n",
      "  Codec - Sample rate: 44100, Hop length: 768\n",
      "  Coarse model - n_codebooks: 4\n",
      "  Vocabulary size: 1024\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ONNX coarse transformer not found at ../onnx_models_fixed/coarse_transformer_v2_weighted.onnx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mONNX encoder not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_encoder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m onnx_coarse_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mONNX coarse transformer not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_coarse_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m onnx_encoder = ort.InferenceSession(\u001b[38;5;28mstr\u001b[39m(onnx_encoder_path))\n\u001b[32m     33\u001b[39m onnx_coarse = ort.InferenceSession(\u001b[38;5;28mstr\u001b[39m(onnx_coarse_path))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: ONNX coarse transformer not found at ../onnx_models_fixed/coarse_transformer_v2_weighted.onnx"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Test Audio (100 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exactly 100 tokens worth of audio\n",
    "n_tokens = 100\n",
    "hop_length = 768\n",
    "n_samples = n_tokens * hop_length  # 76,800 samples\n",
    "sample_rate = 44100\n",
    "duration = n_samples / sample_rate\n",
    "\n",
    "print(f\"Creating test audio: {n_samples} samples ({duration:.2f} seconds)\")\n",
    "\n",
    "# Create a musical test signal\n",
    "t = np.linspace(0, duration, n_samples)\n",
    "audio = np.zeros_like(t)\n",
    "\n",
    "# Add harmonics to create a richer sound\n",
    "fundamentals = [220, 330, 440]  # A3, E4, A4\n",
    "for i, freq in enumerate(fundamentals):\n",
    "    # Fundamental\n",
    "    audio += 0.3 * np.sin(2 * np.pi * freq * t) / (i + 1)\n",
    "    # Harmonics\n",
    "    audio += 0.1 * np.sin(2 * np.pi * freq * 2 * t) / (i + 1)\n",
    "    audio += 0.05 * np.sin(2 * np.pi * freq * 3 * t) / (i + 1)\n",
    "\n",
    "# Add some envelope\n",
    "envelope = np.exp(-t * 0.5) * (1 + 0.2 * np.sin(2 * np.pi * 6 * t))\n",
    "audio = audio * envelope\n",
    "\n",
    "# Normalize\n",
    "audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "audio = audio.astype(np.float32)\n",
    "\n",
    "print(f\"Audio shape: {audio.shape}\")\n",
    "print(f\"Duration: {duration:.2f} seconds\")\n",
    "print(f\"Expected tokens: {n_tokens}\")\n",
    "\n",
    "# Plot the audio\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t[:4410], audio[:4410])  # First 0.1 seconds\n",
    "plt.title('Test Audio Waveform (first 0.1s)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encode Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode with VampNet\n",
    "print(\"Encoding with VampNet...\")\n",
    "audio_tensor = torch.from_numpy(audio).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = codec.encode(audio_tensor, sample_rate)\n",
    "    vampnet_codes = result[\"codes\"]\n",
    "\n",
    "print(f\"VampNet codes shape: {vampnet_codes.shape}\")\n",
    "\n",
    "# Encode with ONNX\n",
    "print(\"\\nEncoding with ONNX...\")\n",
    "audio_onnx = audio.reshape(1, 1, -1)\n",
    "onnx_codes = onnx_encoder.run(None, {'audio_padded': audio_onnx})[0]\n",
    "\n",
    "print(f\"ONNX codes shape: {onnx_codes.shape}\")\n",
    "\n",
    "# Verify they match\n",
    "match_rate = (vampnet_codes.cpu().numpy() == onnx_codes).mean()\n",
    "print(f\"\\nEncoder match rate: {match_rate:.1%}\")\n",
    "\n",
    "# Use VampNet codes for transformer testing\n",
    "codes = vampnet_codes\n",
    "codes_numpy = codes.cpu().numpy()\n",
    "\n",
    "# Extract just the coarse codes (first 4 codebooks)\n",
    "n_coarse = 4\n",
    "coarse_codes = codes[:, :n_coarse, :]\n",
    "coarse_codes_numpy = codes_numpy[:, :n_coarse, :]\n",
    "\n",
    "print(f\"\\nCoarse codes shape: {coarse_codes.shape}\")\n",
    "print(f\"Coarse codes range: [{coarse_codes.min()}, {coarse_codes.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Different Masking Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_periodic_mask(shape, period, offset=0, mask_ratio=None):\n",
    "    \"\"\"\n",
    "    Create a periodic mask pattern.\n",
    "    \n",
    "    Args:\n",
    "        shape: (batch, codebooks, sequence) shape\n",
    "        period: Mask every `period`-th token\n",
    "        offset: Start offset for the pattern\n",
    "        mask_ratio: If provided, use this ratio instead of periodic\n",
    "    \"\"\"\n",
    "    batch, n_codebooks, seq_len = shape\n",
    "    mask = np.zeros(shape, dtype=bool)\n",
    "    \n",
    "    if mask_ratio is not None:\n",
    "        # Random masking with given ratio\n",
    "        n_mask = int(seq_len * mask_ratio)\n",
    "        for b in range(batch):\n",
    "            for c in range(n_codebooks):\n",
    "                indices = np.random.choice(seq_len, n_mask, replace=False)\n",
    "                mask[b, c, indices] = True\n",
    "    else:\n",
    "        # Periodic masking\n",
    "        for i in range(seq_len):\n",
    "            if (i + offset) % period == 0:\n",
    "                mask[:, :, i] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Create different masking patterns\n",
    "mask_patterns = {\n",
    "    \"every_2\": create_periodic_mask(coarse_codes.shape, period=2),\n",
    "    \"every_3\": create_periodic_mask(coarse_codes.shape, period=3),\n",
    "    \"every_4\": create_periodic_mask(coarse_codes.shape, period=4),\n",
    "    \"every_5\": create_periodic_mask(coarse_codes.shape, period=5),\n",
    "    \"random_30\": create_periodic_mask(coarse_codes.shape, period=None, mask_ratio=0.3),\n",
    "    \"random_50\": create_periodic_mask(coarse_codes.shape, period=None, mask_ratio=0.5),\n",
    "    \"random_70\": create_periodic_mask(coarse_codes.shape, period=None, mask_ratio=0.7),\n",
    "}\n",
    "\n",
    "# Visualize masks\n",
    "fig, axes = plt.subplots(len(mask_patterns), 1, figsize=(15, len(mask_patterns) * 1.5))\n",
    "\n",
    "for idx, (name, mask) in enumerate(mask_patterns.items()):\n",
    "    ax = axes[idx]\n",
    "    # Show mask for first codebook\n",
    "    ax.imshow(mask[0, :1, :], aspect='auto', cmap='RdBu', interpolation='nearest')\n",
    "    ax.set_title(f'{name} - {mask.mean():.1%} masked')\n",
    "    ax.set_ylabel('Codebook')\n",
    "    if idx == len(mask_patterns) - 1:\n",
    "        ax.set_xlabel('Token Index')\n",
    "    ax.set_yticks([0])\n",
    "    ax.set_yticklabels(['CB 0'])\n",
    "\n",
    "plt.suptitle('Masking Patterns (Blue = Masked, Red = Unmasked)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test VampNet Transformer with Different Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Check if coarse model expects embeddings or raw codes\n",
    "print(\"Checking VampNet coarse model structure...\")\n",
    "print(f\"Model type: {type(coarse_model)}\")\n",
    "\n",
    "# Test with VampNet's native generation\n",
    "print(\"\\nTesting VampNet transformer with different masks...\")\n",
    "\n",
    "vampnet_results = {}\n",
    "\n",
    "for name, mask in mask_patterns.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Create masked input\n",
    "    masked_codes = coarse_codes.clone()\n",
    "    mask_torch = torch.from_numpy(mask).to(device)\n",
    "    \n",
    "    # Apply mask (set to mask token)\n",
    "    mask_token = coarse_model.vocab_size  # Usually 1024\n",
    "    masked_codes[mask_torch] = mask_token\n",
    "    \n",
    "    print(f\"  Masked tokens: {mask_torch.sum().item()} / {mask_torch.numel()} ({mask_torch.float().mean():.1%})\")\n",
    "    print(f\"  Unique values in masked codes: {torch.unique(masked_codes).cpu().numpy()}\")\n",
    "    \n",
    "    # Run through transformer\n",
    "    with torch.no_grad():\n",
    "        # The coarse model expects the codes directly, not embeddings\n",
    "        # It will handle the embedding internally\n",
    "        try:\n",
    "            # Try the standard forward pass\n",
    "            output = coarse_model(masked_codes)\n",
    "            \n",
    "            # Get predictions for masked positions\n",
    "            predicted_codes = output.argmax(dim=-1)\n",
    "            \n",
    "            # Calculate accuracy on masked positions\n",
    "            masked_positions = mask_torch\n",
    "            correct = (predicted_codes[masked_positions] == coarse_codes[masked_positions]).float()\n",
    "            accuracy = correct.mean().item()\n",
    "            \n",
    "            print(f\"  Accuracy on masked positions: {accuracy:.1%}\")\n",
    "            \n",
    "            vampnet_results[name] = {\n",
    "                'masked_codes': masked_codes.cpu().numpy(),\n",
    "                'predictions': predicted_codes.cpu().numpy(),\n",
    "                'accuracy': accuracy\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error with standard forward: {e}\")\n",
    "            print(f\"  Trying alternative approach...\")\n",
    "            \n",
    "            # Try using the interface's generate method\n",
    "            # This handles the generation process properly\n",
    "            from vampnet import mask as mask_module\n",
    "            \n",
    "            # Create a proper mask using VampNet's masking\n",
    "            mask_obj = mask_module.random(coarse_codes, mask_torch.float().mean().item())\n",
    "            \n",
    "            # Generate\n",
    "            generated = interface.coarse_to_fine(\n",
    "                coarse_codes,\n",
    "                mask=mask_obj\n",
    "            )\n",
    "            \n",
    "            print(f\"  Generated shape: {generated.shape}\")\n",
    "            vampnet_results[name] = {'generated': generated.cpu().numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test ONNX Transformer with Different Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing ONNX transformer with different masks...\")\n",
    "\n",
    "# Check ONNX model inputs\n",
    "print(\"\\nONNX Coarse model inputs:\")\n",
    "for inp in onnx_coarse.get_inputs():\n",
    "    print(f\"  {inp.name}: shape={inp.shape}, type={inp.type}\")\n",
    "\n",
    "onnx_results = {}\n",
    "\n",
    "for name, mask in mask_patterns.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Prepare inputs for ONNX\n",
    "    # ONNX expects raw codes, not embeddings\n",
    "    codes_input = coarse_codes_numpy.astype(np.int64)\n",
    "    mask_input = mask.astype(bool)\n",
    "    \n",
    "    print(f\"  Codes shape: {codes_input.shape}, dtype: {codes_input.dtype}\")\n",
    "    print(f\"  Mask shape: {mask_input.shape}, dtype: {mask_input.dtype}\")\n",
    "    print(f\"  Masked ratio: {mask_input.mean():.1%}\")\n",
    "    \n",
    "    try:\n",
    "        # Run ONNX model\n",
    "        outputs = onnx_coarse.run(None, {\n",
    "            'codes': codes_input,\n",
    "            'mask': mask_input\n",
    "        })\n",
    "        \n",
    "        generated_codes = outputs[0]\n",
    "        print(f\"  Output shape: {generated_codes.shape}\")\n",
    "        print(f\"  Output range: [{generated_codes.min()}, {generated_codes.max()}]\")\n",
    "        \n",
    "        # Check for mask tokens (1024) in output\n",
    "        mask_token = 1024\n",
    "        n_mask_tokens = (generated_codes == mask_token).sum()\n",
    "        print(f\"  Mask tokens in output: {n_mask_tokens}\")\n",
    "        \n",
    "        # Calculate how many tokens were actually changed\n",
    "        changed = (generated_codes != codes_input).sum()\n",
    "        print(f\"  Tokens changed: {changed} / {codes_input.size} ({changed/codes_input.size:.1%})\")\n",
    "        \n",
    "        onnx_results[name] = {\n",
    "            'input_codes': codes_input,\n",
    "            'generated_codes': generated_codes,\n",
    "            'mask': mask_input,\n",
    "            'n_changed': changed\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        onnx_results[name] = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare VampNet vs ONNX Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for each masking pattern\n",
    "print(\"Comparing VampNet vs ONNX results...\\n\")\n",
    "\n",
    "for name in mask_patterns.keys():\n",
    "    print(f\"{name}:\")\n",
    "    \n",
    "    if name in vampnet_results and name in onnx_results:\n",
    "        vamp_res = vampnet_results[name]\n",
    "        onnx_res = onnx_results[name]\n",
    "        \n",
    "        if 'error' not in onnx_res:\n",
    "            # Compare generated codes\n",
    "            if 'predictions' in vamp_res:\n",
    "                vamp_codes = vamp_res['predictions']\n",
    "            elif 'generated' in vamp_res:\n",
    "                vamp_codes = vamp_res['generated'][:, :n_coarse, :]\n",
    "            else:\n",
    "                print(\"  VampNet: No valid output\")\n",
    "                continue\n",
    "                \n",
    "            onnx_codes = onnx_res['generated_codes']\n",
    "            \n",
    "            # Calculate match rate\n",
    "            if vamp_codes.shape == onnx_codes.shape:\n",
    "                matches = (vamp_codes == onnx_codes)\n",
    "                match_rate = matches.mean()\n",
    "                print(f\"  Match rate: {match_rate:.1%}\")\n",
    "                \n",
    "                # Check match rate on masked positions only\n",
    "                mask = mask_patterns[name]\n",
    "                masked_matches = matches[mask]\n",
    "                masked_match_rate = masked_matches.mean() if len(masked_matches) > 0 else 0\n",
    "                print(f\"  Match rate (masked positions): {masked_match_rate:.1%}\")\n",
    "            else:\n",
    "                print(f\"  Shape mismatch: VampNet {vamp_codes.shape} vs ONNX {onnx_codes.shape}\")\n",
    "        else:\n",
    "            print(f\"  ONNX error: {onnx_res['error']}\")\n",
    "    else:\n",
    "        print(\"  Missing results from one or both models\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Token Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize token distributions for one masking pattern\n",
    "test_pattern = \"every_4\"\n",
    "\n",
    "if test_pattern in onnx_results and 'error' not in onnx_results[test_pattern]:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get data\n",
    "    original = coarse_codes_numpy[0]  # Shape: (4, 100)\n",
    "    onnx_gen = onnx_results[test_pattern]['generated_codes'][0]\n",
    "    mask = mask_patterns[test_pattern][0]\n",
    "    \n",
    "    for cb in range(4):\n",
    "        ax = axes[cb]\n",
    "        \n",
    "        # Plot original and generated\n",
    "        x = np.arange(100)\n",
    "        ax.plot(x, original[cb], 'b-', label='Original', alpha=0.7)\n",
    "        ax.plot(x, onnx_gen[cb], 'r--', label='Generated', alpha=0.7)\n",
    "        \n",
    "        # Highlight masked positions\n",
    "        masked_indices = np.where(mask[cb])[0]\n",
    "        ax.scatter(masked_indices, original[cb, masked_indices], \n",
    "                  color='blue', s=100, marker='o', edgecolor='black', \n",
    "                  label='Original (masked)', zorder=5)\n",
    "        ax.scatter(masked_indices, onnx_gen[cb, masked_indices], \n",
    "                  color='red', s=100, marker='x', \n",
    "                  label='Generated (masked)', zorder=5)\n",
    "        \n",
    "        ax.set_title(f'Codebook {cb}')\n",
    "        ax.set_xlabel('Token Index')\n",
    "        ax.set_ylabel('Token Value')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Token Generation with {test_pattern} Masking', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\nStatistics for {test_pattern} masking:\")\n",
    "    print(f\"Total masked positions: {mask.sum()}\")\n",
    "    print(f\"Generated tokens range: [{onnx_gen.min()}, {onnx_gen.max()}]\")\n",
    "    \n",
    "    # Check if any mask tokens (1024) remain\n",
    "    mask_token = 1024\n",
    "    remaining_masks = (onnx_gen == mask_token).sum()\n",
    "    print(f\"Remaining mask tokens: {remaining_masks}\")\n",
    "    \n",
    "    # Token diversity\n",
    "    for cb in range(4):\n",
    "        unique_orig = len(np.unique(original[cb]))\n",
    "        unique_gen = len(np.unique(onnx_gen[cb]))\n",
    "        print(f\"Codebook {cb} - Unique tokens: Original={unique_orig}, Generated={unique_gen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Embedding Issue\n",
    "\n",
    "Check if the transformer is using raw codes instead of embeddings (a known issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if codes are being used directly instead of embeddings\n",
    "print(\"Testing for direct code usage vs embeddings...\\n\")\n",
    "\n",
    "# Create a simple test case\n",
    "test_codes = np.array([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] * 10]], dtype=np.int64)  # Shape: (1, 1, 100)\n",
    "test_codes = np.tile(test_codes, (1, 4, 1))  # Shape: (1, 4, 100)\n",
    "\n",
    "# Create a mask for positions 0, 2, 4, 6, 8\n",
    "test_mask = np.zeros((1, 4, 100), dtype=bool)\n",
    "test_mask[:, :, ::2] = True  # Mask every other position\n",
    "\n",
    "print(f\"Test codes shape: {test_codes.shape}\")\n",
    "print(f\"Test codes sample: {test_codes[0, 0, :10]}\")\n",
    "print(f\"Masked positions: {np.where(test_mask[0, 0])[0][:10]}\")\n",
    "\n",
    "# Run through ONNX\n",
    "try:\n",
    "    test_output = onnx_coarse.run(None, {\n",
    "        'codes': test_codes,\n",
    "        'mask': test_mask\n",
    "    })\n",
    "    \n",
    "    generated = test_output[0]\n",
    "    print(f\"\\nGenerated shape: {generated.shape}\")\n",
    "    print(f\"Generated sample: {generated[0, 0, :10]}\")\n",
    "    \n",
    "    # Check if the generated values are suspiciously similar to input codes\n",
    "    # If codes are used directly, we might see patterns related to the input values\n",
    "    matches = (generated == test_codes)\n",
    "    print(f\"\\nExact matches with input: {matches.mean():.1%}\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    print(f\"\\nValue ranges:\")\n",
    "    print(f\"  Input: [{test_codes.min()}, {test_codes.max()}]\")\n",
    "    print(f\"  Generated: [{generated.min()}, {generated.max()}]\")\n",
    "    \n",
    "    # If embeddings are working correctly, generated values should be in [0, 1023]\n",
    "    # If codes are used directly, we might see strange patterns\n",
    "    if generated.max() > 1023:\n",
    "        print(\"\\n⚠️ WARNING: Generated values exceed vocabulary size!\")\n",
    "        print(\"This suggests the model might be using codes directly instead of embeddings.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Decode and Listen to Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode one of the generated results\n",
    "test_pattern = \"every_4\"\n",
    "\n",
    "if test_pattern in onnx_results and 'error' not in onnx_results[test_pattern]:\n",
    "    print(f\"Decoding results for {test_pattern} masking...\")\n",
    "    \n",
    "    # Get the generated coarse codes\n",
    "    generated_coarse = onnx_results[test_pattern]['generated_codes']\n",
    "    \n",
    "    # We need all 14 codebooks for decoding\n",
    "    # Use original fine codes (codebooks 4-13)\n",
    "    full_codes = codes_numpy.copy()\n",
    "    full_codes[:, :n_coarse, :] = generated_coarse\n",
    "    \n",
    "    # Convert to torch\n",
    "    full_codes_torch = torch.from_numpy(full_codes).long().to(device)\n",
    "    \n",
    "    # Decode\n",
    "    with torch.no_grad():\n",
    "        audio_dict = interface.decode(full_codes_torch)\n",
    "        reconstructed = audio_dict.audio_data.squeeze().cpu().numpy()\n",
    "    \n",
    "    print(f\"Original audio shape: {audio.shape}\")\n",
    "    print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
    "    \n",
    "    # Save audio files\n",
    "    output_dir = Path(\"outputs/transformer_masking_test\")\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    sf.write(output_dir / \"original.wav\", audio, sample_rate)\n",
    "    sf.write(output_dir / f\"generated_{test_pattern}.wav\", reconstructed[:len(audio)], sample_rate)\n",
    "    \n",
    "    # Also decode with original codes for comparison\n",
    "    with torch.no_grad():\n",
    "        audio_dict_orig = interface.decode(codes)\n",
    "        reconstructed_orig = audio_dict_orig.audio_data.squeeze().cpu().numpy()\n",
    "    \n",
    "    sf.write(output_dir / \"reconstructed_original_codes.wav\", reconstructed_orig[:len(audio)], sample_rate)\n",
    "    \n",
    "    print(f\"\\nAudio files saved to {output_dir}\")\n",
    "    print(\"  - original.wav: Original test audio\")\n",
    "    print(f\"  - generated_{test_pattern}.wav: Generated with {test_pattern} masking\")\n",
    "    print(\"  - reconstructed_original_codes.wav: Reconstructed from original codes\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    \n",
    "    t_plot = np.arange(4410) / sample_rate  # First 0.1 seconds\n",
    "    \n",
    "    axes[0].plot(t_plot, audio[:4410])\n",
    "    axes[0].set_title('Original Audio')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(t_plot, reconstructed_orig[:4410], color='green')\n",
    "    axes[1].set_title('Reconstructed (Original Codes)')\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[2].plot(t_plot, reconstructed[:4410], color='red')\n",
    "    axes[2].set_title(f'Generated ({test_pattern} masking)')\n",
    "    axes[2].set_xlabel('Time (s)')\n",
    "    axes[2].set_ylabel('Amplitude')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Audio Comparison (first 0.1s)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRANSFORMER MASKING TEST SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTest configuration:\")\n",
    "print(f\"  Audio duration: {duration:.2f} seconds\")\n",
    "print(f\"  Number of tokens: {n_tokens}\")\n",
    "print(f\"  Coarse codebooks: {n_coarse}\")\n",
    "print(f\"  Encoder match rate: {match_rate:.1%}\")\n",
    "\n",
    "print(f\"\\nMasking patterns tested:\")\n",
    "for name, mask in mask_patterns.items():\n",
    "    print(f\"  {name}: {mask.mean():.1%} masked\")\n",
    "\n",
    "print(f\"\\nKey findings:\")\n",
    "if match_rate > 0.99:\n",
    "    print(\"  ✅ Encoders produce identical results\")\n",
    "else:\n",
    "    print(\"  ❌ Encoder mismatch detected\")\n",
    "\n",
    "# Check for embedding issues\n",
    "has_embedding_issue = False\n",
    "for name, result in onnx_results.items():\n",
    "    if 'generated_codes' in result:\n",
    "        if result['generated_codes'].max() > 1023:\n",
    "            has_embedding_issue = True\n",
    "            break\n",
    "\n",
    "if has_embedding_issue:\n",
    "    print(\"  ⚠️  WARNING: Possible embedding issue detected!\")\n",
    "    print(\"     Generated tokens exceed vocabulary size.\")\n",
    "    print(\"     The model might be using codes directly instead of embeddings.\")\n",
    "else:\n",
    "    print(\"  ✅ Token values within expected range [0, 1023]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}