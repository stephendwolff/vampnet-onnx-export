{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport onnxruntime as ort\nfrom pathlib import Path\nimport sys\nsys.path.append('..')\n\n# Import VampNet\nfrom vampnet.interface import Interface\nfrom vampnet import mask as pmask\n\n# For comparing distributions\nfrom scipy import stats",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load VampNet models\ninterface = Interface(\n    coarse_ckpt=Path(\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/coarse.pth\"),\n    coarse2fine_ckpt=Path(\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/c2f.pth\"),\n    codec_ckpt=Path(\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/codec.pth\"),\n    device=\"cpu\"\n)\n\n# Access the actual models\ncoarse_vamp = interface.coarse\nc2f_vamp = interface.c2f\n\nprint(\"VampNet models loaded\")\nprint(f\"Coarse model: {type(coarse_vamp)}\")\nprint(f\"C2F model: {type(c2f_vamp)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VampNet models\n",
    "interface = Interface(\n",
    "    coarse_ckpt=\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/coarse.pth\",\n",
    "    c2f_ckpt=\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/c2f.pth\",\n",
    "    codec_ckpt=\"/Users/stephen/Documents/Development/MusicHackspace/vampnet-onnx-export-cleanup/models/vampnet/codec.pth\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "# Access the actual models\n",
    "coarse_vamp = interface.coarse\n",
    "c2f_vamp = interface.c2f\n",
    "\n",
    "print(\"VampNet models loaded\")\n",
    "print(f\"Coarse model: {type(coarse_vamp)}\")\n",
    "print(f\"C2F model: {type(c2f_vamp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ONNX models\n",
    "onnx_coarse_session = ort.InferenceSession(\"../onnx_models_fixed/coarse_logits_v3.onnx\")\n",
    "onnx_c2f_session = ort.InferenceSession(\"../onnx_models_fixed/c2f_logits_v3.onnx\")\n",
    "\n",
    "print(\"ONNX models loaded\")\n",
    "print(f\"Coarse inputs: {[inp.name for inp in onnx_coarse_session.get_inputs()]}\")\n",
    "print(f\"C2F inputs: {[inp.name for inp in onnx_c2f_session.get_inputs()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test input\n",
    "batch_size = 1\n",
    "n_tokens = 100\n",
    "n_codebooks = 4\n",
    "\n",
    "# Create random codes\n",
    "codes = torch.randint(0, 1024, (batch_size, n_codebooks, n_tokens))\n",
    "mask_ratio = 0.5\n",
    "\n",
    "# Create mask\n",
    "mask = torch.rand(batch_size, n_codebooks, n_tokens) < mask_ratio\n",
    "\n",
    "print(f\"Test input shape: {codes.shape}\")\n",
    "print(f\"Mask shape: {mask.shape}\")\n",
    "print(f\"Masked positions: {mask.sum().item()} / {mask.numel()} ({mask.float().mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get VampNet logits\n",
    "print(\"Getting VampNet logits...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Apply mask\n",
    "    z_masked = codes.clone()\n",
    "    z_masked[mask] = coarse_vamp.mask_token\n",
    "    \n",
    "    # Get embeddings\n",
    "    z_e = coarse_vamp.embedding.from_codes(z_masked, coarse_vamp.n_codebooks)\n",
    "    z_e = coarse_vamp.embedding.add_positional_encoding(z_e)\n",
    "    \n",
    "    # Run through transformer\n",
    "    z_hat = coarse_vamp.transformer(z_e)\n",
    "    \n",
    "    # Get logits\n",
    "    logits_vampnet = coarse_vamp.classifier(z_hat)\n",
    "    \n",
    "    # Reshape to match expected format\n",
    "    # VampNet outputs (batch, seq_len, n_codebooks * vocab_size)\n",
    "    batch, seq_len, _ = logits_vampnet.shape\n",
    "    logits_vampnet = logits_vampnet.view(batch, seq_len, n_codebooks, coarse_vamp.vocab_size)\n",
    "    logits_vampnet = logits_vampnet.permute(0, 2, 1, 3)  # -> (batch, n_codebooks, seq_len, vocab_size)\n",
    "\n",
    "print(f\"VampNet logits shape: {logits_vampnet.shape}\")\n",
    "print(f\"VampNet logits range: [{logits_vampnet.min():.2f}, {logits_vampnet.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ONNX logits\n",
    "print(\"Getting ONNX logits...\")\n",
    "\n",
    "# Prepare inputs\n",
    "onnx_inputs = {\n",
    "    'codes': codes.numpy().astype(np.int64),\n",
    "    'mask': mask.numpy()\n",
    "}\n",
    "\n",
    "# Run ONNX\n",
    "logits_onnx = onnx_coarse_session.run(None, onnx_inputs)[0]\n",
    "\n",
    "print(f\"ONNX logits shape: {logits_onnx.shape}\")\n",
    "print(f\"ONNX logits range: [{logits_onnx.min():.2f}, {logits_onnx.max():.2f}]\")\n",
    "\n",
    "# Note: ONNX outputs vocab_size+1 (1025) to include mask token\n",
    "# VampNet outputs vocab_size (1024)\n",
    "print(f\"\\nVocab size difference:\")\n",
    "print(f\"  VampNet: {logits_vampnet.shape[-1]}\")\n",
    "print(f\"  ONNX: {logits_onnx.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare logits at masked positions\n",
    "print(\"Comparing logits at masked positions...\\n\")\n",
    "\n",
    "# Get mask positions\n",
    "mask_indices = torch.where(mask)\n",
    "\n",
    "# Compare a few masked positions\n",
    "n_compare = min(5, len(mask_indices[0]))\n",
    "\n",
    "for i in range(n_compare):\n",
    "    b, c, t = mask_indices[0][i], mask_indices[1][i], mask_indices[2][i]\n",
    "    \n",
    "    # Get logits at this position\n",
    "    logits_v = logits_vampnet[b, c, t, :].numpy()\n",
    "    logits_o = logits_onnx[b, c, t, :1024]  # Only compare first 1024 tokens\n",
    "    \n",
    "    # Compare statistics\n",
    "    print(f\"Position [{b}, {c}, {t}]:\")\n",
    "    print(f\"  VampNet: mean={logits_v.mean():.3f}, std={logits_v.std():.3f}, max={logits_v.max():.3f}\")\n",
    "    print(f\"  ONNX:    mean={logits_o.mean():.3f}, std={logits_o.std():.3f}, max={logits_o.max():.3f}\")\n",
    "    \n",
    "    # Top-5 predictions\n",
    "    top5_v = np.argsort(logits_v)[-5:][::-1]\n",
    "    top5_o = np.argsort(logits_o)[-5:][::-1]\n",
    "    print(f\"  VampNet top-5: {top5_v.tolist()}\")\n",
    "    print(f\"  ONNX top-5: {top5_o.tolist()}\")\n",
    "    print(f\"  Agreement: {len(set(top5_v) & set(top5_o))}/5\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison of logits\n",
    "print(\"Statistical comparison of all logits...\\n\")\n",
    "\n",
    "# Flatten logits at masked positions\n",
    "logits_v_masked = logits_vampnet[mask].numpy()\n",
    "logits_o_masked = logits_onnx[mask.numpy()][:, :1024]  # Only first 1024\n",
    "\n",
    "print(f\"Number of masked positions: {mask.sum().item()}\")\n",
    "print(f\"Logits shape per position: {logits_v_masked.shape[1]} (VampNet), {logits_o_masked.shape[1]} (ONNX)\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nOverall statistics:\")\n",
    "print(f\"  VampNet: mean={logits_v_masked.mean():.3f}, std={logits_v_masked.std():.3f}\")\n",
    "print(f\"  ONNX:    mean={logits_o_masked.mean():.3f}, std={logits_o_masked.std():.3f}\")\n",
    "\n",
    "# Distribution comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(logits_v_masked.flatten(), bins=50, alpha=0.5, label='VampNet', density=True)\n",
    "plt.hist(logits_o_masked.flatten(), bins=50, alpha=0.5, label='ONNX', density=True)\n",
    "plt.xlabel('Logit Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Logit Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "# Compare max logits per position\n",
    "max_v = logits_v_masked.max(axis=1)\n",
    "max_o = logits_o_masked.max(axis=1)\n",
    "plt.scatter(max_v, max_o, alpha=0.5)\n",
    "plt.plot([max_v.min(), max_v.max()], [max_v.min(), max_v.max()], 'r--')\n",
    "plt.xlabel('VampNet Max Logit')\n",
    "plt.ylabel('ONNX Max Logit')\n",
    "plt.title('Max Logit Comparison')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Compare entropy\n",
    "probs_v = torch.softmax(torch.from_numpy(logits_v_masked), dim=-1).numpy()\n",
    "probs_o = torch.softmax(torch.from_numpy(logits_o_masked), dim=-1).numpy()\n",
    "entropy_v = -np.sum(probs_v * np.log(probs_v + 1e-10), axis=1)\n",
    "entropy_o = -np.sum(probs_o * np.log(probs_o + 1e-10), axis=1)\n",
    "plt.scatter(entropy_v, entropy_o, alpha=0.5)\n",
    "plt.plot([entropy_v.min(), entropy_v.max()], [entropy_v.min(), entropy_v.max()], 'r--')\n",
    "plt.xlabel('VampNet Entropy')\n",
    "plt.ylabel('ONNX Entropy')\n",
    "plt.title('Distribution Entropy Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation\n",
    "correlation = np.corrcoef(logits_v_masked.flatten(), logits_o_masked.flatten())[0, 1]\n",
    "print(f\"\\nLogit correlation: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from both and compare\n",
    "print(\"Sampling from logits and comparing outputs...\\n\")\n",
    "\n",
    "from scripts.export_vampnet_transformer_v3_sampling import sample_from_onnx_output\n",
    "\n",
    "# Sample from VampNet logits\n",
    "with torch.no_grad():\n",
    "    # VampNet sampling\n",
    "    probs = torch.softmax(logits_vampnet / 0.8, dim=-1)\n",
    "    \n",
    "    # Apply top-p\n",
    "    sorted_probs, sorted_indices = torch.sort(probs, descending=True, dim=-1)\n",
    "    cumsum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "    cutoff_mask = cumsum_probs > 0.9\n",
    "    cutoff_mask[..., 0] = False\n",
    "    sorted_probs[cutoff_mask] = 0\n",
    "    sorted_probs = sorted_probs / sorted_probs.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    # Restore order\n",
    "    probs_vampnet = torch.zeros_like(probs)\n",
    "    probs_vampnet.scatter_(-1, sorted_indices, sorted_probs)\n",
    "    \n",
    "    # Sample\n",
    "    probs_flat = probs_vampnet.view(-1, probs_vampnet.shape[-1])\n",
    "    sampled_flat = torch.multinomial(probs_flat, num_samples=1)\n",
    "    sampled_vampnet = sampled_flat.view(batch_size, n_codebooks, n_tokens)\n",
    "    \n",
    "    # Apply mask\n",
    "    output_vampnet = codes.clone()\n",
    "    output_vampnet[mask] = sampled_vampnet[mask]\n",
    "\n",
    "# Sample from ONNX logits\n",
    "output_onnx = sample_from_onnx_output(\n",
    "    codes.numpy(),\n",
    "    mask.numpy(),\n",
    "    logits_onnx,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Compare\n",
    "changes_vampnet = (output_vampnet != codes).sum().item()\n",
    "changes_onnx = (torch.from_numpy(output_onnx) != codes).sum().item()\n",
    "\n",
    "print(f\"Changes from original:\")\n",
    "print(f\"  VampNet: {changes_vampnet} tokens\")\n",
    "print(f\"  ONNX: {changes_onnx} tokens\")\n",
    "print(f\"  Expected (masked): {mask.sum().item()} tokens\")\n",
    "\n",
    "# Token distribution\n",
    "tokens_vampnet = output_vampnet[mask].numpy()\n",
    "tokens_onnx = output_onnx[mask.numpy()]\n",
    "\n",
    "print(f\"\\nToken distribution at masked positions:\")\n",
    "print(f\"  VampNet: {len(np.unique(tokens_vampnet))} unique tokens\")\n",
    "print(f\"  ONNX: {len(np.unique(tokens_onnx))} unique tokens\")\n",
    "\n",
    "# Most common tokens\n",
    "print(f\"\\nMost common tokens:\")\n",
    "print(f\"  VampNet: {np.bincount(tokens_vampnet).argsort()[-5:][::-1].tolist()}\")\n",
    "print(f\"  ONNX: {np.bincount(tokens_onnx).argsort()[-5:][::-1].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if logits have systematic differences\n",
    "print(\"Checking for systematic differences...\\n\")\n",
    "\n",
    "# Average difference\n",
    "diff = logits_o_masked - logits_v_masked\n",
    "print(f\"Average logit difference (ONNX - VampNet): {diff.mean():.4f} ± {diff.std():.4f}\")\n",
    "\n",
    "# Per-token bias\n",
    "per_token_diff = diff.mean(axis=0)\n",
    "print(f\"\\nPer-token bias range: [{per_token_diff.min():.4f}, {per_token_diff.max():.4f}]\")\n",
    "\n",
    "# Plot per-token bias\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(per_token_diff)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Token ID')\n",
    "plt.ylabel('Average Difference (ONNX - VampNet)')\n",
    "plt.title('Per-Token Logit Bias')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Check if certain tokens are consistently different\n",
    "problematic_tokens = np.where(np.abs(per_token_diff) > 0.5)[0]\n",
    "if len(problematic_tokens) > 0:\n",
    "    print(f\"\\nTokens with large bias (|diff| > 0.5): {problematic_tokens.tolist()}\")\n",
    "else:\n",
    "    print(\"\\nNo tokens with large systematic bias found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nLogit Statistics:\")\n",
    "print(f\"  Correlation: {correlation:.4f}\")\n",
    "print(f\"  Mean difference: {diff.mean():.4f} ± {diff.std():.4f}\")\n",
    "print(f\"  Max absolute difference: {np.abs(diff).max():.4f}\")\n",
    "\n",
    "print(f\"\\nDistribution Comparison:\")\n",
    "print(f\"  VampNet entropy: {entropy_v.mean():.3f} ± {entropy_v.std():.3f}\")\n",
    "print(f\"  ONNX entropy: {entropy_o.mean():.3f} ± {entropy_o.std():.3f}\")\n",
    "\n",
    "print(f\"\\nSampling Results:\")\n",
    "print(f\"  Both models changed approximately the expected number of tokens\")\n",
    "print(f\"  Token diversity is similar between models\")\n",
    "\n",
    "if correlation > 0.9:\n",
    "    print(f\"\\n✅ Logits are highly correlated - models are producing similar outputs\")\n",
    "elif correlation > 0.5:\n",
    "    print(f\"\\n⚠️ Logits are moderately correlated - there may be some differences\")\n",
    "else:\n",
    "    print(f\"\\n❌ Logits are poorly correlated - models are producing very different outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}